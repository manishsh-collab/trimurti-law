# ==============================================================================
# LEGAL CASE AI - Configuration
# Enterprise-grade AI-powered Legal Case Metadata Extraction System
# ==============================================================================

# ------------------------------------------------------------------------------
# API CONFIGURATION
# ------------------------------------------------------------------------------

# Google Gemini API (Primary LLM)
# Get your key at: https://makersuite.google.com/app/apikey
GEMINI_API_KEY=your_gemini_api_key_here

# OpenAI API (Fallback LLM) - Optional
# OPENAI_API_KEY=your_openai_api_key_here

# ------------------------------------------------------------------------------
# MODEL CONFIGURATION
# ------------------------------------------------------------------------------

# Extraction mode: "hybrid" | "llm_only" | "ml_only" | "regex_only"
EXTRACTION_MODE=hybrid

# LLM Model Selection
GEMINI_MODEL=gemini-1.5-flash
# OPENAI_MODEL=gpt-4-turbo-preview

# Confidence threshold for accepting LLM extractions (0.0 - 1.0)
LLM_CONFIDENCE_THRESHOLD=0.85

# ------------------------------------------------------------------------------
# PROCESSING CONFIGURATION
# ------------------------------------------------------------------------------

# Maximum text length for LLM (to manage API costs)
MAX_TEXT_LENGTH=50000

# Enable caching of API responses
ENABLE_CACHE=true
CACHE_TTL_HOURS=24

# Batch processing settings
BATCH_SIZE=10
MAX_CONCURRENT_REQUESTS=5

# ------------------------------------------------------------------------------
# LOGGING CONFIGURATION
# ------------------------------------------------------------------------------

# Log level: DEBUG | INFO | WARNING | ERROR | CRITICAL
LOG_LEVEL=INFO

# Log output: console | file | both
LOG_OUTPUT=both

# Log file path (relative to project root)
LOG_FILE=logs/legal_case_ai.log

# ------------------------------------------------------------------------------
# DATA STORAGE
# ------------------------------------------------------------------------------

# Training data directory
TRAINING_DATA_DIR=data/training

# Extracted results directory
OUTPUT_DIR=data/output

# Model checkpoints directory
MODELS_DIR=models/checkpoints

# ------------------------------------------------------------------------------
# PERFORMANCE TUNING
# ------------------------------------------------------------------------------

# SpaCy model size: "sm" | "md" | "lg"
SPACY_MODEL_SIZE=lg

# Enable GPU acceleration (requires CUDA)
USE_GPU=false

# Number of worker threads
NUM_WORKERS=4
